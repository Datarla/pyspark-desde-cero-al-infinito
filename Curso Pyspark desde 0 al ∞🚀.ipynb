{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fSxDgC300nu"
      },
      "source": [
        "<div style=\"background-color: #f5f7fa; border-left: 6px solid #0077cc; padding: 1.5em; font-family: 'Segoe UI', sans-serif; border-radius: 8px;\">\n",
        "  <h2 style=\"color: #0077cc;\">Configuraciones de Spark</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1H6akJfCegQg"
      },
      "source": [
        "<div style=\"background-color: #f5f7fa; border-left: 6px solid #0077cc; padding: 1.5em; font-family: 'Segoe UI', sans-serif; border-radius: 8px;\">\n",
        "  <h2 style=\"color: #0077cc;\">üí° Cargar configuraci√≥n de Spark desde JSON</h2>\n",
        "  <p>Pod√©s mantener tus configuraciones separadas del c√≥digo usando un archivo <code>.json</code>. Esto es √∫til para:</p>\n",
        "  <ul>\n",
        "    <li>‚úÖ Separar l√≥gica del entorno</li>\n",
        "    <li>‚úÖ Definir distintos ambientes (dev, prod, test)</li>\n",
        "    <li>‚úÖ Evitar hardcodear par√°metros</li>\n",
        "  </ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjifUJgffxT8"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkConf\n",
        "import json\n",
        "\n",
        "conf = SparkConf()\n",
        "\n",
        "file_path = \"/content/sample_data/spark_configs.json\"\n",
        "\n",
        "with open(file_path) as f:\n",
        "  spark_configs = json.load(f)\n",
        "\n",
        "conf.setAll(spark_configs.items())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-4KrQKUh9rJ"
      },
      "source": [
        "<div style=\"background-color: #f0f8ff; border-left: 6px solid #1e90ff; padding: 1.5em; font-family: 'Segoe UI', sans-serif; border-radius: 8px;\">\n",
        "  <h2 style=\"color: #1e90ff;\">üîπ ¬øQu√© es una SparkSession?</h2>\n",
        "  <p>Es el <strong>punto de entrada principal</strong> para trabajar con PySpark.</p>\n",
        "  <ul>\n",
        "    <li>Permite crear y manipular DataFrames</li>\n",
        "    <li>Ejecutar SQL directamente sobre los datos</li>\n",
        "    <li>Leer archivos CSV, JSON, Parquet, entre otros</li>\n",
        "    <li>Acceder a configuraciones internas</li>\n",
        "  </ul>\n",
        "  <h3>üìå Creaci√≥n b√°sica:</h3>\n",
        "  <pre style=\"background-color: #eef6fb; padding: 1em; border-radius: 6px;\">\n",
        "spark = SparkSession.builder \\\\\n",
        "    .appName(\"DataArlaSparkApp\") \\\\\n",
        "    .master(\"local[*]\") \\\\\n",
        "    .getOrCreate()\n",
        "  </pre>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OnEue6nmn-E"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = (\n",
        "    SparkSession.builder\n",
        "    .config(conf=conf)\n",
        "    .getOrCreate()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2cebHkeUdtV"
      },
      "source": [
        "üß† ¬øQu√© es un DataFrame en PySpark?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vCzsHI5bn55"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import *\n",
        "import random\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"id\", IntegerType(), False),\n",
        "    StructField(\"nombre\", StringType(), True),\n",
        "    StructField(\"edad\", IntegerType(), True)\n",
        "])\n",
        "\n",
        "names = [\"nacho\",\"facu\",\"ana\",\"julia\",\"jorge\"]\n",
        "data = [(id, random.choice(names), random.randint(16,55)) for id in range(1,11)]\n",
        "\n",
        "df = spark.createDataFrame(data, schema = schema)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnFtiDk8eu_I"
      },
      "source": [
        "#### Lazy Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szI93rpQerBW"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col\n",
        "menores_edad = df.filter(col(\"edad\") < 18) # transformacion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5f0CzxEfNYX",
        "outputId": "795079f0-3bda-4ff5-8d44-c57e65fadeb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+------+----+\n",
            "| id|nombre|edad|\n",
            "+---+------+----+\n",
            "|  1| jorge|  30|\n",
            "|  6| jorge|  30|\n",
            "| 10|  facu|  36|\n",
            "+---+------+----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "menores_edad.show() # acci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPyOgojpm-BY",
        "outputId": "5e2709f5-6c88-476f-e0db-24a3d27c6694"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import *\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "niQpy7N2n7F3"
      },
      "outputs": [],
      "source": [
        "base_path = '/content/drive/MyDrive/Curso PySpark/datasets for yt'\n",
        "\n",
        "users_path = f'{base_path}/users.csv'\n",
        "tickets_path  = f'{base_path}/tickets.csv'\n",
        "ticket_lines_path =f'{base_path}/ticket_lines.csv'\n",
        "\n",
        "users_dataframe = spark.read.csv(users_path, header=True)\n",
        "users_dataframe.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4euNVbo0L47"
      },
      "source": [
        "<h2>üß† Selecci√≥n de columnas con <code>select()</code> y <code>selectExpr()</code></h2>\n",
        "\n",
        "<p>En PySpark, seleccionamos columnas de un DataFrame para analizarlas o transformarlas. Hay dos m√©todos muy comunes para hacerlo:</p>\n",
        "\n",
        "<h3>üîπ <code>select()</code></h3>\n",
        "<p>Este m√©todo permite seleccionar columnas directamente o construir nuevas columnas con funciones.</p>\n",
        "\n",
        "</code></pre>\n",
        "\n",
        "<p>‚úîÔ∏è Pros:</p>\n",
        "<ul>\n",
        "  <li>M√°s seguro en ambientes donde se evita el uso de expresiones SQL</li>\n",
        "  <li>Facilita el uso de funciones</li>\n",
        "</ul>\n",
        "\n",
        "<h3>üî∏ <code>selectExpr()</code></h3>\n",
        "<p>Permite utilizar expresiones SQL directamente como strings. Ideal para c√°lculos r√°pidos o renombrar columnas.</p>\n",
        "\n",
        "\n",
        "<p>‚úîÔ∏è Pros:</p>\n",
        "<ul>\n",
        "  <li>Muy flexible y potente con expresiones SQL</li>\n",
        "  <li>Ideal para hacer c√°lculos y transformaciones r√°pidas</li>\n",
        "</ul>\n",
        "\n",
        "<p>‚ö†Ô∏è Diferencia clave: <code>selectExpr()</code> recibe strings con expresiones SQL, mientras que <code>select()</code> trabaja con objetos de columna.</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjNzpvPUIBWb"
      },
      "outputs": [],
      "source": [
        "users_data_dataframe = (\n",
        "    users_dataframe.select(\n",
        "        col(\"id\").cast(IntegerType())\n",
        "        ,col(\"gender\").alias(\"genero\").cast(IntegerType())\n",
        "        ,col(\"birth_year\").alias(\"fecha_nacimiento\").cast(IntegerType())\n",
        "    )\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MM3UOey9NDmv"
      },
      "outputs": [],
      "source": [
        "users_data_dataframe_expr = users_dataframe.selectExpr(\n",
        "    \"CAST(id AS INT) AS id\",\n",
        "     \"CAST(gender AS INT) AS genero\",\n",
        "     \"CAST(birth_year AS INT) AS fecha_nacimiento\"\n",
        "    ).printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdTYqTptDzbI"
      },
      "source": [
        "<div style=\"font-family: Arial, sans-serif; line-height: 1.6\">\n",
        "  <h2>üß± Transformaciones: <code>withColumn</code> y <code>withColumnRenamed</code></h2>\n",
        "\n",
        "  <h3>üìå ¬øQu√© es <code>withColumn</code>?</h3>\n",
        "  <p>\n",
        "    El m√©todo <code>withColumn(nombre_columna, expresi√≥n)</code> permite:\n",
        "    <ul>\n",
        "      <li>Agregar una nueva columna calculada al DataFrame.</li>\n",
        "      <li>Reemplazar una columna existente si el nombre coincide.</li>\n",
        "    </ul>\n",
        "    La expresi√≥n debe ser un objeto <code>pyspark.sql.Column</code>. Puede contener c√°lculos, condiciones, valores fijos, etc.\n",
        "  </p>\n",
        "\n",
        "\n",
        "  <h3>üîÅ ¬øQu√© es <code>withColumnRenamed</code>?</h3>\n",
        "  <p>\n",
        "    El m√©todo <code>withColumnRenamed(nombre_antiguo, nombre_nuevo)</code> permite cambiar el nombre de una columna. Devuelve un nuevo DataFrame con la columna renombrada.\n",
        "  </p>\n",
        "\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHK5Y4a_PCD7"
      },
      "outputs": [],
      "source": [
        "users_dataframe_data = users_dataframe.withColumn(\"mayor_edad\", year(current_date()) - col(\"birth_year\").cast(IntegerType()) >= 18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUynh309Pozn"
      },
      "outputs": [],
      "source": [
        "users_dataframe_data.withColumnRenamed(\"birth_year\",\"fecha_nacimiento\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-6YsbkDAseY"
      },
      "source": [
        "üß† Agrupaciones de datos y funciones de agregacion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UoGWZtthAs2p"
      },
      "outputs": [],
      "source": [
        "from decimal import Decimal\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "clients_and_products_schema = StructType([\n",
        "    StructField(\"client_id\", IntegerType(), False),\n",
        "    StructField(\"producto\", StringType(), False),\n",
        "    StructField(\"precio_unitario\", DecimalType(10, 2), False),\n",
        "    StructField(\"cantidad\", IntegerType(), False)\n",
        "])\n",
        "\n",
        "clients_and_products_data = [\n",
        "    (101, \"Jugo de naranja\", Decimal(\"2843.08\"), 2),\n",
        "    (102, \"Torta\", Decimal(\"4080.12\"), 1),\n",
        "    (101, \"Medialunas\",  Decimal(\"950.00\"), 6),\n",
        "    (103, \"Medialunas\", Decimal(\"950.00\"), 12),\n",
        "    (102, \"Jugo de naranja\", Decimal(\"2843.08\"), 2),\n",
        "    (101, \"Torta\", Decimal(\"4080.12\"), 1)\n",
        "]\n",
        "\n",
        "df = spark.createDataFrame(schema=clients_and_products_schema, data=clients_and_products_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvjFQ7fyKZtP",
        "outputId": "7674d515-a444-454f-e0f1-6c48f316ec2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+---------------+---------------+--------+\n",
            "|client_id|       producto|precio_unitario|cantidad|\n",
            "+---------+---------------+---------------+--------+\n",
            "|      101|Jugo de naranja|        2843.08|       2|\n",
            "|      102|          Torta|        4080.12|       1|\n",
            "|      101|     Medialunas|         950.00|       6|\n",
            "|      103|     Medialunas|         950.00|      12|\n",
            "|      102|Jugo de naranja|        2843.08|       2|\n",
            "|      101|          Torta|        4080.12|       1|\n",
            "+---------+---------------+---------------+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnUBsotnKiW1",
        "outputId": "4bd67651-09ab-4230-dd8e-a39c5838bd5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+---------------+---------------+--------+------------------+\n",
            "|client_id|       producto|precio_unitario|cantidad|total_por_producto|\n",
            "+---------+---------------+---------------+--------+------------------+\n",
            "|      101|Jugo de naranja|        2843.08|       2|           5686.16|\n",
            "|      102|          Torta|        4080.12|       1|           4080.12|\n",
            "|      101|     Medialunas|         950.00|       6|           5700.00|\n",
            "|      103|     Medialunas|         950.00|      12|          11400.00|\n",
            "|      102|Jugo de naranja|        2843.08|       2|           5686.16|\n",
            "|      101|          Torta|        4080.12|       1|           4080.12|\n",
            "+---------+---------------+---------------+--------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "total_ammount_products_dataframe = df.withColumn(\"total_por_producto\", col(\"precio_unitario\") * col(\"cantidad\"))\n",
        "total_ammount_products_dataframe.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vP6NpH3WK7Ln",
        "outputId": "9f057f0c-d6dc-4725-af89-ece796c1e555"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+-------------+----------------+-------------+-------------+---------------+\n",
            "|client_id|total_gastado|cantidad_compras|precio_minimo|precio_maximo|precio_promedio|\n",
            "+---------+-------------+----------------+-------------+-------------+---------------+\n",
            "|      101|     15466.28|               3|       950.00|      4080.12|    2624.400000|\n",
            "|      102|      9766.28|               2|      2843.08|      4080.12|    3461.600000|\n",
            "|      103|     11400.00|               1|       950.00|       950.00|     950.000000|\n",
            "+---------+-------------+----------------+-------------+-------------+---------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "statics_client_dataframe = (\n",
        "    total_ammount_products_dataframe.groupBy(\"client_id\")\n",
        "      .agg(\n",
        "          sum(\"total_por_producto\").alias(\"total_gastado\"),\n",
        "          count(\"*\").alias(\"cantidad_compras\"),\n",
        "          min(\"precio_unitario\").alias(\"precio_minimo\"),\n",
        "          max(\"precio_unitario\").alias(\"precio_maximo\"),\n",
        "          avg(\"precio_unitario\").alias(\"precio_promedio\")\n",
        "          )\n",
        ")\n",
        "statics_client_dataframe.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
