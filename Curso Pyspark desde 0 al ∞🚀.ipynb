{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: #f5f7fa; border-left: 6px solid #0077cc; padding: 1.5em; font-family: 'Segoe UI', sans-serif; border-radius: 8px;\">\n",
        "  <h2 style=\"color: #0077cc;\">Configuraciones de Spark</p>\n",
        "</div>"
      ],
      "metadata": {
        "id": "9fSxDgC300nu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: #f5f7fa; border-left: 6px solid #0077cc; padding: 1.5em; font-family: 'Segoe UI', sans-serif; border-radius: 8px;\">\n",
        "  <h2 style=\"color: #0077cc;\">üí° Cargar configuraci√≥n de Spark desde JSON</h2>\n",
        "  <p>Pod√©s mantener tus configuraciones separadas del c√≥digo usando un archivo <code>.json</code>. Esto es √∫til para:</p>\n",
        "  <ul>\n",
        "    <li>‚úÖ Separar l√≥gica del entorno</li>\n",
        "    <li>‚úÖ Definir distintos ambientes (dev, prod, test)</li>\n",
        "    <li>‚úÖ Evitar hardcodear par√°metros</li>\n",
        "  </ul>\n",
        "</div>"
      ],
      "metadata": {
        "id": "1H6akJfCegQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkConf\n",
        "import json\n",
        "\n",
        "conf = SparkConf()\n",
        "\n",
        "file_path = \"/content/sample_data/spark_configs.json\"\n",
        "\n",
        "with open(file_path) as f:\n",
        "  spark_configs = json.load(f)\n",
        "\n",
        "conf.setAll(spark_configs.items())"
      ],
      "metadata": {
        "id": "zjifUJgffxT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: #f0f8ff; border-left: 6px solid #1e90ff; padding: 1.5em; font-family: 'Segoe UI', sans-serif; border-radius: 8px;\">\n",
        "  <h2 style=\"color: #1e90ff;\">üîπ ¬øQu√© es una SparkSession?</h2>\n",
        "  <p>Es el <strong>punto de entrada principal</strong> para trabajar con PySpark.</p>\n",
        "  <ul>\n",
        "    <li>Permite crear y manipular DataFrames</li>\n",
        "    <li>Ejecutar SQL directamente sobre los datos</li>\n",
        "    <li>Leer archivos CSV, JSON, Parquet, entre otros</li>\n",
        "    <li>Acceder a configuraciones internas</li>\n",
        "  </ul>\n",
        "  <h3>üìå Creaci√≥n b√°sica:</h3>\n",
        "  <pre style=\"background-color: #eef6fb; padding: 1em; border-radius: 6px;\">\n",
        "spark = SparkSession.builder \\\\\n",
        "    .appName(\"DataArlaSparkApp\") \\\\\n",
        "    .master(\"local[*]\") \\\\\n",
        "    .getOrCreate()\n",
        "  </pre>\n"
      ],
      "metadata": {
        "id": "s-4KrQKUh9rJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = (\n",
        "    SparkSession.builder\n",
        "    .config(conf=conf)\n",
        "    .getOrCreate()\n",
        ")"
      ],
      "metadata": {
        "id": "8OnEue6nmn-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† ¬øQu√© es un DataFrame en PySpark?"
      ],
      "metadata": {
        "id": "v2cebHkeUdtV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "import random\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"id\", IntegerType(), False),\n",
        "    StructField(\"nombre\", StringType(), True),\n",
        "    StructField(\"edad\", IntegerType(), True)\n",
        "])\n",
        "\n",
        "names = [\"nacho\",\"facu\",\"ana\",\"julia\",\"jorge\"]\n",
        "data = [(id, random.choice(names), random.randint(16,55)) for id in range(1,11)]\n",
        "\n",
        "df = spark.createDataFrame(data, schema = schema)"
      ],
      "metadata": {
        "id": "2vCzsHI5bn55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Lazy Evaluation"
      ],
      "metadata": {
        "id": "TnFtiDk8eu_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "menores_edad = df.filter(col(\"edad\") < 18) # transformacion"
      ],
      "metadata": {
        "id": "szI93rpQerBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "menores_edad.show() # acci√≥n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5f0CzxEfNYX",
        "outputId": "795079f0-3bda-4ff5-8d44-c57e65fadeb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+----+\n",
            "| id|nombre|edad|\n",
            "+---+------+----+\n",
            "|  1| jorge|  30|\n",
            "|  6| jorge|  30|\n",
            "| 10|  facu|  36|\n",
            "+---+------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPyOgojpm-BY",
        "outputId": "5e2709f5-6c88-476f-e0db-24a3d27c6694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = '/content/drive/MyDrive/Curso PySpark/datasets for yt'\n",
        "\n",
        "users_path = f'{base_path}/users.csv'\n",
        "tickets_path  = f'{base_path}/tickets.csv'\n",
        "ticket_lines_path =f'{base_path}/ticket_lines.csv'\n",
        "\n",
        "users_dataframe = spark.read.csv(users_path, header=True)\n",
        "users_dataframe.printSchema()"
      ],
      "metadata": {
        "id": "niQpy7N2n7F3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>üß† Selecci√≥n de columnas con <code>select()</code> y <code>selectExpr()</code></h2>\n",
        "\n",
        "<p>En PySpark, seleccionamos columnas de un DataFrame para analizarlas o transformarlas. Hay dos m√©todos muy comunes para hacerlo:</p>\n",
        "\n",
        "<h3>üîπ <code>select()</code></h3>\n",
        "<p>Este m√©todo permite seleccionar columnas directamente o construir nuevas columnas con funciones.</p>\n",
        "\n",
        "</code></pre>\n",
        "\n",
        "<p>‚úîÔ∏è Pros:</p>\n",
        "<ul>\n",
        "  <li>M√°s seguro en ambientes donde se evita el uso de expresiones SQL</li>\n",
        "  <li>Facilita el uso de funciones</li>\n",
        "</ul>\n",
        "\n",
        "<h3>üî∏ <code>selectExpr()</code></h3>\n",
        "<p>Permite utilizar expresiones SQL directamente como strings. Ideal para c√°lculos r√°pidos o renombrar columnas.</p>\n",
        "\n",
        "\n",
        "<p>‚úîÔ∏è Pros:</p>\n",
        "<ul>\n",
        "  <li>Muy flexible y potente con expresiones SQL</li>\n",
        "  <li>Ideal para hacer c√°lculos y transformaciones r√°pidas</li>\n",
        "</ul>\n",
        "\n",
        "<p>‚ö†Ô∏è Diferencia clave: <code>selectExpr()</code> recibe strings con expresiones SQL, mientras que <code>select()</code> trabaja con objetos de columna.</p>\n"
      ],
      "metadata": {
        "id": "y4euNVbo0L47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users_data_dataframe = (\n",
        "    users_dataframe.select(\n",
        "        col(\"id\").cast(IntegerType())\n",
        "        ,col(\"gender\").alias(\"genero\").cast(IntegerType())\n",
        "        ,col(\"birth_year\").alias(\"fecha_nacimiento\").cast(IntegerType())\n",
        "    )\n",
        ")\n"
      ],
      "metadata": {
        "id": "pjNzpvPUIBWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_data_dataframe_expr = users_dataframe.selectExpr(\n",
        "    \"CAST(id AS INT) AS id\",\n",
        "     \"CAST(gender AS INT) AS genero\",\n",
        "     \"CAST(birth_year AS INT) AS fecha_nacimiento\"\n",
        "    ).printSchema()"
      ],
      "metadata": {
        "id": "MM3UOey9NDmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"font-family: Arial, sans-serif; line-height: 1.6\">\n",
        "  <h2>üß± Transformaciones: <code>withColumn</code> y <code>withColumnRenamed</code></h2>\n",
        "\n",
        "  <h3>üìå ¬øQu√© es <code>withColumn</code>?</h3>\n",
        "  <p>\n",
        "    El m√©todo <code>withColumn(nombre_columna, expresi√≥n)</code> permite:\n",
        "    <ul>\n",
        "      <li>Agregar una nueva columna calculada al DataFrame.</li>\n",
        "      <li>Reemplazar una columna existente si el nombre coincide.</li>\n",
        "    </ul>\n",
        "    La expresi√≥n debe ser un objeto <code>pyspark.sql.Column</code>. Puede contener c√°lculos, condiciones, valores fijos, etc.\n",
        "  </p>\n",
        "\n",
        "\n",
        "  <h3>üîÅ ¬øQu√© es <code>withColumnRenamed</code>?</h3>\n",
        "  <p>\n",
        "    El m√©todo <code>withColumnRenamed(nombre_antiguo, nombre_nuevo)</code> permite cambiar el nombre de una columna. Devuelve un nuevo DataFrame con la columna renombrada.\n",
        "  </p>\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "UdTYqTptDzbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users_dataframe_data = users_dataframe.withColumn(\"mayor_edad\", year(current_date()) - col(\"birth_year\").cast(IntegerType()) >= 18)"
      ],
      "metadata": {
        "id": "RHK5Y4a_PCD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_dataframe_data.withColumnRenamed(\"birth_year\",\"fecha_nacimiento\").show()"
      ],
      "metadata": {
        "id": "dUynh309Pozn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}